
<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>SQIL: Saliency-aware Quantized Imitation Learning</title>
  <link rel="stylesheet" href="css/style.css">
</head>
<body>
  <header class="header">
    <h1>SQIL:Saliency-aware Quantized Imitation Learning</h1>
    <p><strong>Under Review at ICCV 2025</strong></p>
    <p class="links">
      <a href="https://arxiv.org/abs/2505.15304">[Paper]</a>
      <a href="https://github.com/your-org/sqil">[Code]</a>
      <a href="assets/demo.mp4">[Video]</a>
    </p>
  </header>

  <section class="teaser">
    <img src="assets/teaser.png" alt="Teaser Image">
  </section>

  <section class="content">
    <h2>Abstract</h2>
    <p>Deep neural network (DNN)-based policy models, such as vision-language-action (VLA) models, excel at automating complex decision-making from multi-modal inputs. However, scaling these models greatly increases computational overhead, complicating deployment in resource-constrained settings like robot manipulation and autonomous driving. To address this, we propose Saliency-Aware Quantized Imitation Learning (\method), which combines quantization-aware training with a selective loss-weighting strategy for mission-critical states. By identifying these states via saliency scores and emphasizing them in the training loss, \method preserves decision fidelity under low-bit precision. We validate \method's generalization capability across extensive simulation benchmarks with environment variations, real-world tasks, and cross-domain tasks (self-driving, physics simulation), consistently recovering full-precision performance. Notably, a 4-bit weight-quantized VLA model for robotic manipulation achieves up to 2.5$\times$ speedup and 2.5$\times$ energy savings on an edge GPU with minimal accuracy loss. These results underline \methodâ€™s potential for efficiently deploying large IL-based policy models on resource-limited devices.</p>

    <h2>Highlights</h2>
    <ul>
      <li>4-bit policy with minimal accuracy drop</li>
      <li>State importance via perturbation saliency</li>
      <li>Robust generalization across simulation and real-world tasks</li>
    </ul>

    <h2>Demo Video</h2>
    <video controls width="100%">
      <source src="assets/demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>

    <h2>BibTeX</h2>
    <pre>
@inproceedings{park2025sqil,
  title={Saliency-aware Quantized Imitation Learning},
  author={Park, Seongmin and ...},
  booktitle={ICCV},
  year={2025}
}
    </pre>
  </section>

  <footer>
    <p>&copy; 2025 Seongmin Park, VLA Lab</p>
  </footer>
</body>
</html>
