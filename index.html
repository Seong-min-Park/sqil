<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>SQIL: Saliency-aware Quantized Imitation Learning</title>
  <link rel="stylesheet" href="css/style.css">
  <style>
    .slider {
      position: relative;
      overflow: hidden;
      margin-top: 3em;
    }
    .slider-track {
      display: flex;
      transition: transform 0.5s ease;
    }
    .slide {
      min-width: 100%;
      display: flex;
      justify-content: space-around;
      gap: 1em;
      padding: 1em 0;
    }
    .slide video {
      width: 22%;
      border: 1px solid #ccc;
    }
    .slider-nav {
      position: absolute;
      top: 50%;
      transform: translateY(-50%);
      background: rgba(255, 255, 255, 0.8);
      border: none;
      font-size: 2em;
      cursor: pointer;
    }
    .slider-nav.left { left: 10px; }
    .slider-nav.right { right: 10px; }
    .task-title {
      text-align: center;
      font-weight: bold;
      font-size: 1.2em;
      margin-bottom: 0.5em;
    }
  </style>
</head>
<body>
  <header class="header">
    <h1>SQIL:</h1>
    <h2>Saliency-aware Quantized Imitation Learning</h2>
    <p><strong>Under Review at ICCV 2025</strong></p>
    <p class="links">
      <a href="https://arxiv.org/abs/2505.15304">[Paper]</a>
      <a href="https://github.com/your-org/sqil">[Code]</a>
      <a href="assets/demo.mp4">[Video]</a>
    </p>
  </header>

  <section class="teaser">
    <img src="assets/fig_1.PNG" alt="Teaser Image">
  </section>

  <section class="content">
    <h2>Abstract</h2>
    <p>Deep neural network (DNN)-based policy models, such as vision-language-action (VLA) models, excel at automating complex decision-making from multi-modal inputs. However, scaling these models greatly increases computational overhead, complicating deployment in resource-constrained settings like robot manipulation and autonomous driving. To address this, we propose Saliency-Aware Quantized Imitation Learning (SQIL), which combines quantization-aware training with a selective loss-weighting strategy for mission-critical states. By identifying these states via saliency scores and emphasizing them in the training loss, SQIL preserves decision fidelity under low-bit precision. We validate SQIL's generalization capability across extensive simulation benchmarks with environment variations, real-world tasks, and cross-domain tasks (self-driving, physics simulation), consistently recovering full-precision performance. Notably, a 4-bit weight-quantized VLA model for robotic manipulation achieves up to 2.5x speedup and 2.5x energy savings on an edge GPU with minimal accuracy loss. These results underline SQILâ€™s potential for efficiently deploying large IL-based policy models on resource-limited devices.</p>

    <h2>Highlights</h2>
    <ul>
      <li>4-bit policy with minimal accuracy drop</li>
      <li>State importance via perturbation saliency</li>
      <li>Robust generalization across simulation and real-world tasks</li>
    </ul>

    <h2>Rollout Video</h2>

    <h3>Real-World Robot Manipulation</h3>
    <div class="slider">
      <div class="task-title" id="real-title">Task: Stack purple cup on green cup</div>
      <button class="slider-nav left" onclick="slideReal(-1)">&#8592;</button>
      <button class="slider-nav right" onclick="slideReal(1)">&#8594;</button>
      <div class="slider-track" id="real-slider">
        <div class="slide">
          <video src="assets/real1_fp.mp4" autoplay muted loop></video>
          <video src="assets/real1_ptq.mp4" autoplay muted loop></video>
          <video src="assets/real1_sqil.mp4" autoplay muted loop></video>
        </div>
        <div class="slide">
          <video src="assets/real2_fp.mp4" autoplay muted loop></video>
          <video src="assets/real2_ptq.mp4" autoplay muted loop></video>
          <video src="assets/real2_sqil.mp4" autoplay muted loop></video>
        </div>
      </div>
    </div>

    <h3>Simulation-based Robot Manipulation (LIBERO)</h3>
    <div class="slider">
      <div class="task-title" id="sim-title">Task: Spatial</div>
      <button class="slider-nav left" onclick="slideSim(-1)">&#8592;</button>
      <button class="slider-nav right" onclick="slideSim(1)">&#8594;</button>
      <div class="slider-track" id="sim-slider">
        <div class="slide">
          <video src="assets/spatial_fp.mp4" autoplay muted loop></video>
          <video src="assets/spatial_ptq.mp4" autoplay muted loop></video>
          <video src="assets/spatial_qat.mp4" autoplay muted loop></video>
          <video src="assets/spatial_sqil.mp4" autoplay muted loop></video>
        </div>
        <div class="slide">
          <video src="assets/object_fp.mp4" autoplay muted loop></video>
          <video src="assets/object_ptq.mp4" autoplay muted loop></video>
          <video src="assets/object_qat.mp4" autoplay muted loop></video>
          <video src="assets/object_sqil.mp4" autoplay muted loop></video>
        </div>
        <div class="slide">
          <video src="assets/goal_fp.mp4" autoplay muted loop></video>
          <video src="assets/goal_ptq.mp4" autoplay muted loop></video>
          <video src="assets/goal_qat.mp4" autoplay muted loop></video>
          <video src="assets/goal_sqil.mp4" autoplay muted loop></video>
        </div>
        <div class="slide">
          <video src="assets/long_fp.mp4" autoplay muted loop></video>
          <video src="assets/long_ptq.mp4" autoplay muted loop></video>
          <video src="assets/long_qat.mp4" autoplay muted loop></video>
          <video src="assets/long_sqil.mp4" autoplay muted loop></video>
        </div>
      </div>
    </div>

    <h3>Autonomous Driving</h3>
    <div class="autonomous-driving">
      <img src="assets/driving_baseline.png" alt="Driving Baseline">
      <img src="assets/driving_qat.png" alt="Driving QAT">
      <img src="assets/driving_sqil.png" alt="Driving SQIL">
    </div>

    <h2>Demo Video</h2>
    <video controls width="100%">
      <source src="assets/demo.mp4" type="video/mp4">
      Your browser does not support the video tag.
    </video>

    <h2>BibTeX</h2>
    <pre>
@inproceedings{park2025sqil,
  title={Saliency-aware Quantized Imitation Learning},
  author={Park, Seongmin and ...},
  booktitle={ICCV},
  year={2025}
}
    </pre>
  </section>

  <footer>
    <p>&copy; 2025 Seongmin Park, VLA Lab</p>
  </footer>

  <script>
    const realTitles = ["Task: Stack purple cup on green cup", "Task: Put eggplant into pot"];
    let realIndex = 0;
    function slideReal(dir) {
      realIndex = Math.max(0, Math.min(1, realIndex + dir));
      document.getElementById('real-slider').style.transform = `translateX(-${100 * realIndex}%)`;
      document.getElementById('real-title').textContent = realTitles[realIndex];
    }

    const simTitles = ["Task: Spatial", "Task: Object", "Task: Goal", "Task: Long"];
    let simIndex = 0;
    function slideSim(dir) {
      simIndex = Math.max(0, Math.min(3, simIndex + dir));
      document.getElementById('sim-slider').style.transform = `translateX(-${100 * simIndex}%)`;
      document.getElementById('sim-title').textContent = simTitles[simIndex];
    }
  </script>
</body>
</html>
